{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5kPSC78hAsiU",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-27 19:48:20.769505: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 7078986356470803693\n",
       " xla_global_id: -1,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 6034030592\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 12463218673689836831\n",
       " physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:2b:00.0, compute capability: 8.6\"\n",
       " xla_global_id: 416903419]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-27 19:48:20.803614: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-27 19:48:20.833316: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-27 19:48:20.833485: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-27 19:48:21.185641: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-27 19:48:21.185783: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-27 19:48:21.185893: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-27 19:48:21.185983: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /device:GPU:0 with 5754 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:2b:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "# log_path = 'log.txt'\n",
    "# sys.stdout = open(log_path, \"w\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()\n",
    "\n",
    "# config = tf.compat.v1.ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "# sess = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape is: (91, 69, 100, 100, 5)\n",
      "Splitted trainning dataset shape is: (68, 69, 100, 100, 5)\n",
      "Splitted trainning dataset shape is: (23, 69, 100, 100, 5)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "# load dataset\n",
    "# h5 = h5py.File('./data/NG_07272022.hdf5', mode='r')\n",
    "# h5 = h5py.File('./data/NG_10_07272022.hdf5', mode='r')\n",
    "h5 = h5py.File('./data/NG_07152022.hdf5', mode='r')\n",
    "dataset = h5.get('phi')\n",
    "\n",
    "# shuffle dataset\n",
    "data_sz = dataset.shape[0]\n",
    "# data_sz = int(dataset.shape[0]/2)\n",
    "indexes = np.arange(data_sz)\n",
    "np.random.shuffle(indexes)\n",
    "train_index = np.sort(indexes[: int(0.75 * data_sz)])\n",
    "val_index = np.sort(indexes[int(0.75 * data_sz) :])\n",
    "\n",
    "# check dataset size\n",
    "print(f'Dataset shape is: {dataset.shape}')\n",
    "train_dataset = np.take(dataset,train_index,axis=0)\n",
    "val_dataset = np.take(dataset,val_index,axis=0)\n",
    "print(f'Splitted trainning dataset shape is: {train_dataset.shape}')\n",
    "print(f'Splitted trainning dataset shape is: {val_dataset.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running ...: 100%|██████████| 68/68 [00:02<00:00, 30.35it/s]\n",
      "Running ...: 100%|██████████| 23/23 [00:00<00:00, 31.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Shapes: (4352, 5, 100, 100, 5), (4352, 2, 100, 100, 5)\n",
      "Validation Dataset Shapes: (1472, 5, 100, 100, 5), (1472, 2, 100, 100, 5)\n",
      "Training Dataset Shapes: (3000, 5, 100, 100, 5), (3000, 2, 100, 100, 5)\n",
      "Validation Dataset Shapes: (1000, 5, 100, 100, 5), (1000, 2, 100, 100, 5)\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def create_shifted_frames_many2one(dataset,numFrames):\n",
    "    sz = dataset.shape[0]*(dataset.shape[1]-numFrames)\n",
    "    x = np.zeros([sz, numFrames, 100, 100, 5])\n",
    "    y = np.zeros([sz, 2, 100, 100, 5])\n",
    "    k = 0\n",
    "    for i in tqdm(range(dataset.shape[0]), desc=\"Running ...\"):\n",
    "        for j in range(dataset.shape[1]-numFrames):\n",
    "            currentFrame = np.expand_dims(np.expand_dims(dataset[i,j+numFrames,...],axis=0),axis=0)\n",
    "            pastFrames = np.expand_dims(dataset[i,j:(j+numFrames),...],axis=0)\n",
    "            x[k,...] = pastFrames\n",
    "            y[k,0,...] = currentFrame\n",
    "            y[k,1,...] = pastFrames[:,-1,...] # passing past frame to ground truth for use in loss function (an issue with directly passing inp into loss func)\n",
    "            k+=1  \n",
    "    return x,y\n",
    "\n",
    "# def create_shifted_frames_many2one_append(dataset,numFrames):\n",
    "#     for i in tqdm(range(dataset.shape[0]), desc=\"Running ...\"):\n",
    "#         for j in range(dataset.shape[1]-numFrames):\n",
    "#             currentFrame = np.expand_dims(np.expand_dims(dataset[i,j+numFrames,...],axis=0),axis=0)\n",
    "#             pastFrames = np.expand_dims(dataset[i,j:(j+numFrames),...],axis=0)\n",
    "#             try:\n",
    "#                 x = np.append(x,pastFrames,axis=0)\n",
    "#                 y = np.append(y,currentFrame,axis=0)\n",
    "#                 y1 = np.append(y1,pastFrames[:,-1,...],axis=0)\n",
    "#             except:\n",
    "#                 x = pastFrames\n",
    "#                 y = currentFrame\n",
    "#                 y1 = pastFrames[:,-1,...]\n",
    "#     return x,y\n",
    "\n",
    "# creatign many to 1 shifted trainning and validation dataset\n",
    "numFrames = 5\n",
    "x_train, y_train = create_shifted_frames_many2one(train_dataset,numFrames)\n",
    "x_val, y_val = create_shifted_frames_many2one(val_dataset,numFrames)\n",
    "\n",
    "# increase tubulin magnitude (actual value too small)\n",
    "x_train[...,2] = x_train[...,2]*10\n",
    "y_train[...,2] = y_train[...,2]*10\n",
    "x_val[...,2] = x_val[...,2]*10\n",
    "y_val[...,2] = y_val[...,2]*10\n",
    "\n",
    "print(\"Training Dataset Shapes: \" + str(x_train.shape) + \", \" + str(y_train.shape))\n",
    "print(\"Validation Dataset Shapes: \" + str(x_val.shape) + \", \" + str(y_val.shape))\n",
    "\n",
    "# some wierd memory issue with tensorflow, same batch size with smaller dataset size works\n",
    "x_train = np.take(x_train,np.arange(3000),axis=0)\n",
    "y_train = np.take(y_train,np.arange(3000),axis=0)\n",
    "x_val = np.take(x_val,np.arange(1000),axis=0)\n",
    "y_val = np.take(y_val,np.arange(1000),axis=0)\n",
    "\n",
    "print(\"Training Dataset Shapes: \" + str(x_train.shape) + \", \" + str(y_train.shape))\n",
    "print(\"Validation Dataset Shapes: \" + str(x_val.shape) + \", \" + str(y_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 5, 100, 100, 5)\n",
      "2668\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Goal Frame 5')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x240 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "data_choice = np.random.choice(range(len(x_train)), size=1)[0]\n",
    "print(data_choice)\n",
    "channel = 0\n",
    "plt.figure(figsize=(20, 4), dpi=60)\n",
    "for i in range(numFrames):\n",
    "    plt.subplot(1,numFrames+1,i+1)\n",
    "    plt.imshow(x_train[data_choice,i,:,:,channel])\n",
    "    plt.colorbar()\n",
    "    plt.title(f\"Trainning Frame {i}\")\n",
    "\n",
    "plt.subplot(1,numFrames+1,numFrames+1)\n",
    "plt.imshow(y_train[data_choice,0,:,:,channel])\n",
    "plt.colorbar()\n",
    "plt.title(f\"Goal Frame {numFrames}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sum_filter_python(phi):\n",
    "#     phi = phi.numpy()\n",
    "#     Nx = phi.shape[0]\n",
    "#     Ny = phi.shape[1]\n",
    "#     phi = np.round(phi)\n",
    "\n",
    "#     phi_sum = np.zeros([Nx,Ny])\n",
    "#     for i in range(5,Nx-4):\n",
    "#         for k in range(5,Ny-4):\n",
    "#             for j in range(k-4,k+4+1):\n",
    "#                 phi_sum[i,k] = phi_sum[i,k] + int(phi[i,k]==phi[i-4,j])*phi[i-4,j] + int(phi[i,k]==phi[i-3,j])*phi[i-3,j] + int(phi[i,k]==phi[i-2,j])*phi[i-2,j] + int(phi[i,k]==phi[i-1,j])*phi[i-1,j] + int(phi[i,k]==phi[i-0,j])*phi[i,j] + int(phi[i,k]==phi[i+1,j])*phi[i+1,j] + int(phi[i,k]==phi[i+2,j])*phi[i+2,j] + int(phi[i,k]==phi[i+3,j])*phi[i+3,j] + int(phi[i,k]==phi[i+4,j])*phi[i+4,j]\n",
    "\n",
    "#     phi_sum = np.divide(phi,phi_sum)\n",
    "#     phi_sum[np.isnan(phi_sum)] = 0\n",
    "#     phi_sum_max = np.amax(np.amax(phi_sum))\n",
    "#     phi_sum = np.divide(phi_sum,phi_sum_max)\n",
    "\n",
    "#     phi_sum_temp = phi_sum\n",
    "#     cutoff = np.percentile(np.reshape(phi_sum_temp,[Nx*Ny,1]),99.97)\n",
    "#     phi_sum[phi_sum<cutoff] = 0\n",
    "#     phi_sum[phi_sum!=1] = 0  \n",
    "#     out = tf.Variable(tf.zeros([Nx,Ny],tf.float64))\n",
    "#     out.assign(phi_sum)\n",
    "#     return out\n",
    "\n",
    "# def highlightZone(tip):\n",
    "#     [Max_y,Max_x] = np.where(tip==1)\n",
    "#     size_Max = len(Max_x)\n",
    "#     Nx, Ny = phi_plot.shape\n",
    "#     tips = np.zeros([Nx,Ny])\n",
    "#     temp = np.zeros([Nx,Ny])\n",
    "#     for l in range(0,size_Max):\n",
    "#         max_x = Max_x[l]\n",
    "#         max_y = Max_y[l]\n",
    "#         for i in range(max_y-2,max_y+2):\n",
    "#             for j in range(max_x-2,max_x+2):\n",
    "#                     temp[i,j] = 1\n",
    "#         tips = tips+temp\n",
    "\n",
    "#     tips[np.abs(tips)>0] = 1\n",
    "#     return tips\n",
    "\n",
    "# def sum_filter_python(phi):\n",
    "#     [Nx,Ny] = tf.shape(phi)\n",
    "#     phi = tf.math.round(phi)\n",
    "#     phi_sum = tf.Variable(tf.zeros([Nx,Ny],tf.float32))\n",
    "#     for i in range(5,Nx-4):\n",
    "#         for k in range(5,Ny-4):\n",
    "#             for j in range(k-4,k+4+1):\n",
    "#                 phi_sum[i,k].assign(tf.math.add(tf.cast(phi[i,k],tf.float32),tf.multiply(tf.cast(phi[i,k]==phi[i-4,j],tf.float32),phi[i-4,j])))\n",
    "\n",
    "#     return phi_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate partial derivatives of the input\n",
    "def get_deriv(input):\n",
    "    N1N_input, NN1_input = tf.image.image_gradients(input)\n",
    "    N2N_input, _ = tf.image.image_gradients(N1N_input)\n",
    "    _, NN2_input = tf.image.image_gradients(NN1_input)\n",
    "    LAP_input = tf.math.add(N2N_input,NN2_input)\n",
    "    return N1N_input, NN1_input, N2N_input, NN2_input, LAP_input\n",
    "\n",
    "# calculate MSE\n",
    "def get_MSE_tf(input,goal):\n",
    "    return tf.math.reduce_mean(tf.square(tf.math.subtract(input, goal)))\n",
    "\n",
    "def get_MRE_tf(input,goal):\n",
    "    return tf.math.sqrt(tf.reduce_sum(tf.math.reduce_mean(tf.math.square(input-goal))))\n",
    "    \n",
    "# PINN - physics-informed loss function for Phase-field neuron growth model\n",
    "def PINN_loss():\n",
    "    def loss(y_true, y_pred):\n",
    "        dt = 0.01*10 # current data sampled per 500 iter (change based on dataset)\n",
    "        y_true = tf.cast(y_true, dtype=tf.float64)\n",
    "        y_pred = tf.cast(y_pred, dtype=tf.float64)\n",
    "\n",
    "        # # extract variables from ground truth\n",
    "        true_phi = tf.expand_dims(y_true[:,0,:,:,0],axis=3)\n",
    "        true_tips = tf.expand_dims(y_true[:,0,:,:,1],axis=3)\n",
    "        true_tub = tf.expand_dims(y_true[:,0,:,:,2],axis=3)\n",
    "        true_tempr = tf.expand_dims(y_true[:,0,:,:,3],axis=3)\n",
    "        theta = tf.expand_dims(y_true[:,0,:,:,4],axis=3) # Since theta is passed, theta remains the same\n",
    "        # extract variables from previous iteration (intentionally placed in ground truth so it is easier to access)\n",
    "        NN_p = tf.expand_dims(y_true[:,1,:,:,0],axis=3)\n",
    "        tips_p = tf.expand_dims(y_true[:,1,:,:,1],axis=3)\n",
    "        tub_p = tf.expand_dims(y_true[:,1,:,:,2],axis=3)\n",
    "        tempr_p = tf.expand_dims(y_true[:,1,:,:,3],axis=3)\n",
    "        # extract variables from prediction\n",
    "        NN_pK = tf.expand_dims(y_pred[:,-1,:,:,0],axis=3)\n",
    "        tips_pK = tf.expand_dims(y_pred[:,-1,:,:,1],axis=3)\n",
    "        tub_pK = tf.expand_dims(y_pred[:,-1,:,:,2],axis=3)\n",
    "        tempr_pK = tf.expand_dims(y_pred[:,-1,:,:,3],axis=3)\n",
    "\n",
    "        # calc corresponding partial derivatives\n",
    "        N1N_p, NN1_p, _, _, LAP_p = get_deriv(NN_p)\n",
    "        N1N_theta, NN1_theta, _, _, _ = get_deriv(theta)\n",
    "        _, _, _, _, LAP_tp = get_deriv(tempr_p)\n",
    "        N1N_tb, NN1_tb, _, _, LAP_tb = get_deriv(tub_p)\n",
    "\n",
    "        # Temperature residual\n",
    "        tempr_residual = (3*LAP_tp+4*(NN_pK - NN_p)/dt)*dt + tempr_p - tempr_pK\n",
    "\n",
    "        # Tubulin residual\n",
    "        diff_tb = 4*(tf.math.multiply(N1N_p,N1N_tb) + tf.math.multiply(NN1_p,NN1_tb) + tf.math.multiply(NN_p,LAP_tb))\n",
    "        alph_tb = 0.001*(tf.math.multiply(N1N_p,tub_p) + tf.math.multiply(NN_p,N1N_tb) + tf.math.multiply(NN1_p,tub_p) + tf.math.multiply(NN_p,NN1_tb))\n",
    "        beta_tb = 0.001*tf.math.multiply(NN_p,tub_p)\n",
    "        src_tb = tf.math.divide_no_nan(15*tf.math.square(LAP_p),tf.math.reduce_sum(tf.math.square(LAP_p)))\n",
    "        tub_residual = (diff_tb - alph_tb - beta_tb + src_tb)*dt + tub_p - tub_pK\n",
    "\n",
    "        # phase field residual\n",
    "        e = 0.2865*tf.math.atan(10*tf.math.multiply(tf.math.multiply(tips_p,5*tub_pK-0.1),1-tempr_pK)) # energy equation\n",
    "        atheta = tf.math.atan2(NN1_p,N1N_p)\n",
    "        a = 0.04*(1.0+0.1*tf.math.cos(6*(atheta-theta)))\n",
    "        ap = -0.04*(6*0.1*tf.math.sin(6*(atheta-theta)))\n",
    "        aap = tf.math.multiply(a,ap)\n",
    "        a2 = tf.math.square(a)\n",
    "        a2Lap = tf.math.multiply(a2,LAP_p)\n",
    "        N1N_aapNN1p, _ = tf.image.image_gradients(tf.math.multiply(aap,NN1_p))\n",
    "        _, NN1_aapN1Np = tf.image.image_gradients(tf.math.multiply(aap,N1N_p))\n",
    "        mag_theta = tf.math.sqrt(tf.math.square(N1N_theta) + tf.math.square(NN1_theta))\n",
    "        dblwll_term = tf.math.multiply(tf.math.multiply(NN_p,1-NN_p),NN_p - 0.5 + e + 6*0.007*mag_theta)\n",
    "        phi_residual = a2Lap - N1N_aapNN1p + NN1_aapN1Np + dblwll_term - (NN_pK - NN_p) / dt\n",
    "\n",
    "        # calculate mean of each residual and mse of prediction and ground truth\n",
    "        residual_mse = tf.math.reduce_mean(phi_residual) + tf.math.reduce_mean(tempr_residual) + tf.math.reduce_mean(tub_residual)\n",
    "        diff_mse = get_MSE_tf(NN_pK,true_phi) + get_MSE_tf(tips_pK,true_tips) + get_MSE_tf(tempr_pK,true_tempr) + get_MRE_tf(tub_pK,true_tub)\n",
    "        # diff_mse = get_MSE_tf(NN_pK,true_phi) + get_MSE_tf(tempr_pK,true_tempr) + get_MRE_tf(tub_pK,true_tub)\n",
    "        loss = tf.math.abs(residual_mse) + tf.math.abs(diff_mse)\n",
    "        \n",
    "        return loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-27 19:48:45.736490: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-27 19:48:45.736671: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-27 19:48:45.736774: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-27 19:48:45.737020: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-27 19:48:45.737137: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-27 19:48:45.737237: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-27 19:48:45.737377: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-27 19:48:45.737486: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-27 19:48:45.737569: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5754 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:2b:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "inp = layers.Input(shape=(x_train.shape[1:]))\n",
    "\n",
    "# Separable Convolution Encoding\n",
    "x0 = layers.TimeDistributed(layers.Conv2D(\n",
    "    filters=64,\n",
    "    kernel_size=(5, 5),\n",
    "    strides = (2, 2),\n",
    "    padding=\"valid\",\n",
    "    activation=\"relu\",\n",
    "))(inp)\n",
    "x1 = layers.TimeDistributed(layers.Conv2D(\n",
    "    filters=128,\n",
    "    kernel_size=(5, 5),\n",
    "    strides = (2, 2),\n",
    "    padding=\"valid\",\n",
    "    activation=\"relu\",\n",
    "))(x0)\n",
    "# recurrent cell, 5 time step to 1 time step\n",
    "x2 = layers.ConvLSTM2D(\n",
    "    filters=128,\n",
    "    kernel_size=(5, 5),\n",
    "    padding=\"same\",\n",
    "    return_sequences=False,\n",
    "    activation=\"relu\",\n",
    "    # recurrent_dropout=drop_rate,\n",
    ")(x1)\n",
    "x2 = tf.expand_dims(x2,axis=1)\n",
    "\n",
    "# passing theta (no change)\n",
    "theta1 = tf.expand_dims(tf.expand_dims(inp[:,0,:,:,-1],axis=1),axis=4)\n",
    "\n",
    "# decoding for phi channel\n",
    "phi1 = x2\n",
    "phi2 = layers.TimeDistributed(layers.Conv2DTranspose(\n",
    "    filters=64,\n",
    "    kernel_size=(6, 6),\n",
    "    strides = (2, 2),\n",
    "    padding=\"valid\",\n",
    "    activation=\"sigmoid\",\n",
    "))(phi1)\n",
    "phi3 = layers.TimeDistributed(layers.Conv2DTranspose(\n",
    "    filters=1,\n",
    "    kernel_size=(6, 6),\n",
    "    strides = (2, 2),\n",
    "    padding=\"valid\",\n",
    "    activation=\"sigmoid\",\n",
    "))(phi2)\n",
    "\n",
    "# decoding for tips channel\n",
    "phi_pre = tf.expand_dims(tf.expand_dims(inp[:,-1,:,:,0],axis=1),axis=4)\n",
    "tip1 = layers.TimeDistributed(layers.Conv2D(\n",
    "    filters=1,\n",
    "    kernel_size=(6, 6),\n",
    "    strides = (1, 1),\n",
    "    padding=\"same\",\n",
    "    activation=\"sigmoid\",\n",
    "))(phi_pre)\n",
    "tip2 = layers.TimeDistributed(layers.Conv2DTranspose(\n",
    "    filters=1,\n",
    "    kernel_size=(6, 6),\n",
    "    strides = (1, 1),\n",
    "    padding=\"same\",\n",
    "    activation=\"sigmoid\",\n",
    "))(tip1)\n",
    "\n",
    "# decoding for tublin channel\n",
    "tub1 = x2\n",
    "tub2 = layers.TimeDistributed(layers.Conv2DTranspose(\n",
    "    filters=64,\n",
    "    kernel_size=(6, 6),\n",
    "    strides = (2, 2),\n",
    "    padding=\"valid\",\n",
    "    activation=\"relu\",\n",
    "    use_bias=True,\n",
    "))(tub1)\n",
    "tub3 = layers.TimeDistributed(layers.Conv2DTranspose(\n",
    "    filters=1,\n",
    "    kernel_size=(6, 6),\n",
    "    strides = (2, 2),\n",
    "    padding=\"valid\",\n",
    "    activation=\"relu\",\n",
    "    use_bias=True,\n",
    "))(tub2)\n",
    "tub4 = tf.math.multiply(phi3,tub3)\n",
    "\n",
    "# decoding for temperature channel\n",
    "phi_diff = phi3 - phi_pre\n",
    "tempr1 = x2\n",
    "tempr2 = layers.TimeDistributed(layers.Conv2DTranspose(\n",
    "    filters=64,\n",
    "    kernel_size=(6, 6),\n",
    "    strides = (2, 2),\n",
    "    padding=\"valid\",\n",
    "    activation=\"relu\",\n",
    "))(tempr1)\n",
    "tempr3 = layers.TimeDistributed(layers.Conv2DTranspose(\n",
    "    filters=1,\n",
    "    kernel_size=(6, 6),\n",
    "    strides = (2, 2),\n",
    "    padding=\"valid\",\n",
    "    activation=\"relu\",\n",
    "))(tempr2)\n",
    "tempr3 = tf.concat([tempr3,phi_diff],axis=4)\n",
    "tempr4 = layers.TimeDistributed(layers.Conv2DTranspose(\n",
    "    filters=1,\n",
    "    kernel_size=(6, 6),\n",
    "    strides = (1, 1),\n",
    "    padding=\"same\",\n",
    "    activation=\"relu\",\n",
    "))(tempr3)\n",
    "\n",
    "# concat all to generate output\n",
    "out = tf.concat([phi3,tip2,tub4,tempr4,theta1],axis=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 5, 100, 100  0           []                               \n",
      "                                , 5)]                                                             \n",
      "                                                                                                  \n",
      " time_distributed (TimeDistribu  (None, 5, 48, 48, 6  8064       ['input_1[0][0]']                \n",
      " ted)                           4)                                                                \n",
      "                                                                                                  \n",
      " time_distributed_1 (TimeDistri  (None, 5, 22, 22, 1  204928     ['time_distributed[0][0]']       \n",
      " buted)                         28)                                                               \n",
      "                                                                                                  \n",
      " conv_lstm2d (ConvLSTM2D)       (None, 22, 22, 128)  3277312     ['time_distributed_1[0][0]']     \n",
      "                                                                                                  \n",
      " tf.expand_dims (TFOpLambda)    (None, 1, 22, 22, 1  0           ['conv_lstm2d[0][0]']            \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1 (Sl  (None, 100, 100)    0           ['input_1[0][0]']                \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " time_distributed_2 (TimeDistri  (None, 1, 48, 48, 6  294976     ['tf.expand_dims[0][0]']         \n",
      " buted)                         4)                                                                \n",
      "                                                                                                  \n",
      " tf.expand_dims_3 (TFOpLambda)  (None, 1, 100, 100)  0           ['tf.__operators__.getitem_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " time_distributed_3 (TimeDistri  (None, 1, 100, 100,  2305       ['time_distributed_2[0][0]']     \n",
      " buted)                          1)                                                               \n",
      "                                                                                                  \n",
      " tf.expand_dims_4 (TFOpLambda)  (None, 1, 100, 100,  0           ['tf.expand_dims_3[0][0]']       \n",
      "                                 1)                                                               \n",
      "                                                                                                  \n",
      " time_distributed_8 (TimeDistri  (None, 1, 48, 48, 6  294976     ['tf.expand_dims[0][0]']         \n",
      " buted)                         4)                                                                \n",
      "                                                                                                  \n",
      " time_distributed_6 (TimeDistri  (None, 1, 48, 48, 6  294976     ['tf.expand_dims[0][0]']         \n",
      " buted)                         4)                                                                \n",
      "                                                                                                  \n",
      " time_distributed_9 (TimeDistri  (None, 1, 100, 100,  2305       ['time_distributed_8[0][0]']     \n",
      " buted)                          1)                                                               \n",
      "                                                                                                  \n",
      " tf.math.subtract (TFOpLambda)  (None, 1, 100, 100,  0           ['time_distributed_3[0][0]',     \n",
      "                                 1)                               'tf.expand_dims_4[0][0]']       \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  (None, 100, 100)    0           ['input_1[0][0]']                \n",
      " ingOpLambda)                                                                                     \n",
      "                                                                                                  \n",
      " time_distributed_4 (TimeDistri  (None, 1, 100, 100,  37         ['tf.expand_dims_4[0][0]']       \n",
      " buted)                          1)                                                               \n",
      "                                                                                                  \n",
      " time_distributed_7 (TimeDistri  (None, 1, 100, 100,  2305       ['time_distributed_6[0][0]']     \n",
      " buted)                          1)                                                               \n",
      "                                                                                                  \n",
      " tf.concat (TFOpLambda)         (None, 1, 100, 100,  0           ['time_distributed_9[0][0]',     \n",
      "                                 2)                               'tf.math.subtract[0][0]']       \n",
      "                                                                                                  \n",
      " tf.expand_dims_1 (TFOpLambda)  (None, 1, 100, 100)  0           ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " time_distributed_5 (TimeDistri  (None, 1, 100, 100,  37         ['time_distributed_4[0][0]']     \n",
      " buted)                          1)                                                               \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLambda)  (None, 1, 100, 100,  0           ['time_distributed_3[0][0]',     \n",
      "                                 1)                               'time_distributed_7[0][0]']     \n",
      "                                                                                                  \n",
      " time_distributed_10 (TimeDistr  (None, 1, 100, 100,  73         ['tf.concat[0][0]']              \n",
      " ibuted)                         1)                                                               \n",
      "                                                                                                  \n",
      " tf.expand_dims_2 (TFOpLambda)  (None, 1, 100, 100,  0           ['tf.expand_dims_1[0][0]']       \n",
      "                                 1)                                                               \n",
      "                                                                                                  \n",
      " tf.concat_1 (TFOpLambda)       (None, 1, 100, 100,  0           ['time_distributed_3[0][0]',     \n",
      "                                 5)                               'time_distributed_5[0][0]',     \n",
      "                                                                  'tf.math.multiply[0][0]',       \n",
      "                                                                  'time_distributed_10[0][0]',    \n",
      "                                                                  'tf.expand_dims_2[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,382,294\n",
      "Trainable params: 4,382,294\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Model(inp, out)\n",
    "model.compile(\n",
    "    loss=PINN_loss(),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-4))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "X5Q7hmIAAsiX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-27 19:48:51.777587: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:903] layout failed: INVALID_ARGUMENT: MutableGraphView::SortTopologically error: detected edge(s) creating cycle(s) {'Func/gradient_tape/model/conv_lstm2d/while/model/conv_lstm2d/while_grad/body/_189/input/_551' -> 'gradient_tape/model/conv_lstm2d/while/model/conv_lstm2d/while_grad/body/_189/gradient_tape/model/conv_lstm2d/while/gradients/AddN', 'model/conv_lstm2d/while/body/_1/model/conv_lstm2d/while/mul_2' -> 'model/conv_lstm2d/while/body/_1/model/conv_lstm2d/while/add_5', 'model/conv_lstm2d/while/body/_1/model/conv_lstm2d/while/clip_by_value_2' -> 'model/conv_lstm2d/while/body/_1/model/conv_lstm2d/while/mul_5', 'model/conv_lstm2d/while/body/_1/model/conv_lstm2d/while/convolution_6' -> 'model/conv_lstm2d/while/body/_1/model/conv_lstm2d/while/add_4', 'model/conv_lstm2d/while/body/_1/model/conv_lstm2d/while/clip_by_value' -> 'model/conv_lstm2d/while/body/_1/model/conv_lstm2d/while/mul_3'}.\n",
      "2022-07-27 19:48:52.600937: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "599/600 [============================>.] - ETA: 0s - loss: 0.7110"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-27 19:49:17.756161: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:903] layout failed: INVALID_ARGUMENT: MutableGraphView::SortTopologically error: detected edge(s) creating cycle(s) {'model/conv_lstm2d/while/body/_1/model/conv_lstm2d/while/Relu_1' -> 'model/conv_lstm2d/while/body/_1/model/conv_lstm2d/while/mul_5', 'model/conv_lstm2d/while/body/_1/model/conv_lstm2d/while/mul_2' -> 'model/conv_lstm2d/while/body/_1/model/conv_lstm2d/while/add_5', 'model/conv_lstm2d/while/body/_1/model/conv_lstm2d/while/convolution_7' -> 'model/conv_lstm2d/while/body/_1/model/conv_lstm2d/while/add_6'}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 31s 45ms/step - loss: 0.7104 - val_loss: 0.4143 - lr: 1.0000e-04\n",
      "Epoch 2/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.2678 - val_loss: 0.1770 - lr: 1.0000e-04\n",
      "Epoch 3/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.1300 - val_loss: 0.1144 - lr: 1.0000e-04\n",
      "Epoch 4/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0959 - val_loss: 0.0977 - lr: 1.0000e-04\n",
      "Epoch 5/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0819 - val_loss: 0.0789 - lr: 1.0000e-04\n",
      "Epoch 6/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0743 - val_loss: 0.0852 - lr: 1.0000e-04\n",
      "Epoch 7/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0697 - val_loss: 0.0682 - lr: 1.0000e-04\n",
      "Epoch 8/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0643 - val_loss: 0.0716 - lr: 1.0000e-04\n",
      "Epoch 9/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0610 - val_loss: 0.0698 - lr: 1.0000e-04\n",
      "Epoch 10/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0579 - val_loss: 0.0602 - lr: 1.0000e-04\n",
      "Epoch 11/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0560 - val_loss: 0.0584 - lr: 1.0000e-04\n",
      "Epoch 12/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0535 - val_loss: 0.0550 - lr: 1.0000e-04\n",
      "Epoch 13/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0513 - val_loss: 0.0572 - lr: 1.0000e-04\n",
      "Epoch 14/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0489 - val_loss: 0.0522 - lr: 1.0000e-04\n",
      "Epoch 15/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0471 - val_loss: 0.0547 - lr: 1.0000e-04\n",
      "Epoch 16/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0464 - val_loss: 0.0522 - lr: 1.0000e-04\n",
      "Epoch 17/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0447 - val_loss: 0.0454 - lr: 1.0000e-04\n",
      "Epoch 18/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0432 - val_loss: 0.0459 - lr: 1.0000e-04\n",
      "Epoch 19/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0414 - val_loss: 0.0488 - lr: 1.0000e-04\n",
      "Epoch 20/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0395 - val_loss: 0.0441 - lr: 1.0000e-04\n",
      "Epoch 21/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0385 - val_loss: 0.0435 - lr: 1.0000e-04\n",
      "Epoch 22/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0364 - val_loss: 0.0447 - lr: 1.0000e-04\n",
      "Epoch 23/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0362 - val_loss: 0.0462 - lr: 1.0000e-04\n",
      "Epoch 24/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0352 - val_loss: 0.0397 - lr: 1.0000e-04\n",
      "Epoch 25/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0329 - val_loss: 0.0401 - lr: 1.0000e-04\n",
      "Epoch 26/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0328 - val_loss: 0.0400 - lr: 1.0000e-04\n",
      "Epoch 27/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0328 - val_loss: 0.0379 - lr: 1.0000e-04\n",
      "Epoch 28/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0311 - val_loss: 0.0400 - lr: 1.0000e-04\n",
      "Epoch 29/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0304 - val_loss: 0.0365 - lr: 1.0000e-04\n",
      "Epoch 30/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0303 - val_loss: 0.0353 - lr: 1.0000e-04\n",
      "Epoch 31/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0293 - val_loss: 0.0367 - lr: 1.0000e-04\n",
      "Epoch 32/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0298 - val_loss: 0.0366 - lr: 1.0000e-04\n",
      "Epoch 33/1000\n",
      "600/600 [==============================] - 25s 41ms/step - loss: 0.0285 - val_loss: 0.0339 - lr: 1.0000e-04\n",
      "Epoch 34/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0277 - val_loss: 0.0356 - lr: 1.0000e-04\n",
      "Epoch 35/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0278 - val_loss: 0.0339 - lr: 1.0000e-04\n",
      "Epoch 36/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0272 - val_loss: 0.0412 - lr: 1.0000e-04\n",
      "Epoch 37/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0277 - val_loss: 0.0333 - lr: 1.0000e-04\n",
      "Epoch 38/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0272 - val_loss: 0.0330 - lr: 1.0000e-04\n",
      "Epoch 39/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0268 - val_loss: 0.0354 - lr: 1.0000e-04\n",
      "Epoch 40/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0260 - val_loss: 0.0312 - lr: 1.0000e-04\n",
      "Epoch 41/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0257 - val_loss: 0.0326 - lr: 1.0000e-04\n",
      "Epoch 42/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0254 - val_loss: 0.0330 - lr: 1.0000e-04\n",
      "Epoch 43/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0246 - val_loss: 0.0303 - lr: 1.0000e-04\n",
      "Epoch 44/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0247 - val_loss: 0.0316 - lr: 1.0000e-04\n",
      "Epoch 45/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0241 - val_loss: 0.0332 - lr: 1.0000e-04\n",
      "Epoch 46/1000\n",
      "600/600 [==============================] - 25s 41ms/step - loss: 0.0240 - val_loss: 0.0319 - lr: 1.0000e-04\n",
      "Epoch 47/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0246 - val_loss: 0.0346 - lr: 1.0000e-04\n",
      "Epoch 48/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0246 - val_loss: 0.0297 - lr: 1.0000e-04\n",
      "Epoch 49/1000\n",
      "600/600 [==============================] - 25s 41ms/step - loss: 0.0240 - val_loss: 0.0312 - lr: 1.0000e-04\n",
      "Epoch 50/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0235 - val_loss: 0.0292 - lr: 1.0000e-04\n",
      "Epoch 51/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0222 - val_loss: 0.0303 - lr: 1.0000e-04\n",
      "Epoch 52/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0228 - val_loss: 0.0291 - lr: 1.0000e-04\n",
      "Epoch 53/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0233 - val_loss: 0.0329 - lr: 1.0000e-04\n",
      "Epoch 54/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0230 - val_loss: 0.0291 - lr: 1.0000e-04\n",
      "Epoch 55/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0230 - val_loss: 0.0298 - lr: 1.0000e-04\n",
      "Epoch 56/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0218 - val_loss: 0.0314 - lr: 1.0000e-04\n",
      "Epoch 57/1000\n",
      "600/600 [==============================] - 26s 43ms/step - loss: 0.0216 - val_loss: 0.0290 - lr: 1.0000e-04\n",
      "Epoch 58/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0220 - val_loss: 0.0286 - lr: 1.0000e-04\n",
      "Epoch 59/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0209 - val_loss: 0.0308 - lr: 1.0000e-04\n",
      "Epoch 60/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0209 - val_loss: 0.0287 - lr: 1.0000e-04\n",
      "Epoch 61/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0207 - val_loss: 0.0289 - lr: 1.0000e-04\n",
      "Epoch 62/1000\n",
      "600/600 [==============================] - 25s 41ms/step - loss: 0.0221 - val_loss: 0.0285 - lr: 1.0000e-04\n",
      "Epoch 63/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0206 - val_loss: 0.0292 - lr: 1.0000e-04\n",
      "Epoch 64/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0200 - val_loss: 0.0287 - lr: 1.0000e-04\n",
      "Epoch 65/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0200 - val_loss: 0.0271 - lr: 1.0000e-04\n",
      "Epoch 66/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0195 - val_loss: 0.0284 - lr: 1.0000e-04\n",
      "Epoch 67/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0208 - val_loss: 0.0278 - lr: 1.0000e-04\n",
      "Epoch 68/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0194 - val_loss: 0.0283 - lr: 1.0000e-04\n",
      "Epoch 69/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0195 - val_loss: 0.0285 - lr: 1.0000e-04\n",
      "Epoch 70/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0197 - val_loss: 0.0280 - lr: 1.0000e-04\n",
      "Epoch 71/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0161 - val_loss: 0.0267 - lr: 1.0000e-05\n",
      "Epoch 72/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0158 - val_loss: 0.0266 - lr: 1.0000e-05\n",
      "Epoch 73/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0156 - val_loss: 0.0264 - lr: 1.0000e-05\n",
      "Epoch 74/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0156 - val_loss: 0.0266 - lr: 1.0000e-05\n",
      "Epoch 75/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0153 - val_loss: 0.0263 - lr: 1.0000e-05\n",
      "Epoch 76/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0152 - val_loss: 0.0263 - lr: 1.0000e-05\n",
      "Epoch 77/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0153 - val_loss: 0.0263 - lr: 1.0000e-05\n",
      "Epoch 78/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0153 - val_loss: 0.0263 - lr: 1.0000e-05\n",
      "Epoch 79/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0151 - val_loss: 0.0265 - lr: 1.0000e-05\n",
      "Epoch 80/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0151 - val_loss: 0.0261 - lr: 1.0000e-05\n",
      "Epoch 81/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0150 - val_loss: 0.0264 - lr: 1.0000e-05\n",
      "Epoch 82/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0150 - val_loss: 0.0261 - lr: 1.0000e-05\n",
      "Epoch 83/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0150 - val_loss: 0.0264 - lr: 1.0000e-05\n",
      "Epoch 84/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0150 - val_loss: 0.0264 - lr: 1.0000e-05\n",
      "Epoch 85/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0149 - val_loss: 0.0263 - lr: 1.0000e-05\n",
      "Epoch 86/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0146 - val_loss: 0.0262 - lr: 1.0000e-06\n",
      "Epoch 87/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0145 - val_loss: 0.0263 - lr: 1.0000e-06\n",
      "Epoch 88/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0145 - val_loss: 0.0261 - lr: 1.0000e-06\n",
      "Epoch 89/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0145 - val_loss: 0.0262 - lr: 1.0000e-06\n",
      "Epoch 90/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0145 - val_loss: 0.0261 - lr: 1.0000e-06\n",
      "Epoch 91/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0145 - val_loss: 0.0262 - lr: 1.0000e-07\n",
      "Epoch 92/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0144 - val_loss: 0.0262 - lr: 1.0000e-07\n",
      "Epoch 93/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0145 - val_loss: 0.0262 - lr: 1.0000e-07\n",
      "Epoch 94/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0145 - val_loss: 0.0262 - lr: 1.0000e-07\n",
      "Epoch 95/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0145 - val_loss: 0.0262 - lr: 1.0000e-07\n",
      "Epoch 96/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0145 - val_loss: 0.0262 - lr: 1.0000e-08\n",
      "Epoch 97/1000\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0145 - val_loss: 0.0262 - lr: 1.0000e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 11). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_model/model_conv_lstm_test_26/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_model/model_conv_lstm_test_26/assets\n"
     ]
    }
   ],
   "source": [
    "test = False\n",
    "\n",
    "if test == True:\n",
    "    model = keras.models.load_model('./saved_model/model_conv_lstm_test_27', custom_objects={'loss': PINN_loss()})\n",
    "else: \n",
    "    early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=15)\n",
    "    reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=5)\n",
    "    epochs = 1000\n",
    "    batch_size = 5\n",
    "    with tf.device('/device:GPU:0'):\n",
    "        model.fit(\n",
    "            x_train,\n",
    "            y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_data=(x_val, y_val),\n",
    "            callbacks=[early_stopping, reduce_lr],\n",
    "        )\n",
    "    model.save('./saved_model/model_conv_lstm_test_27') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random case: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Plotting and Saving figures ...:  31%|███▏      | 20/64 [00:20<00:39,  1.13it/s]/tmp/ipykernel_113091/1424540685.py:42: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize=(25, 12), dpi=60)\n",
      "Plotting and Saving figures ...:  61%|██████    | 39/64 [00:36<00:28,  1.12s/it]"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "# start matlab engine, requires valid installation of matlab and matlab.engine library\n",
    "import matlab.engine\n",
    "eng = matlab.engine.start_matlab()\n",
    "s = eng.genpath('Matlab_algorithm/prev')\n",
    "eng.addpath(s, nargout=0)\n",
    "\n",
    "# calc mre between pred and goal\n",
    "def get_mre(pred,goal):\n",
    "    return np.sqrt(np.sum(np.square(pred-goal)/(pred.shape[0]*pred.shape[1])))\n",
    "\n",
    "def push(input, cutoff):\n",
    "    # input = input.numpy()\n",
    "    # max_input = np.amax(input)\n",
    "    output = copy.copy(input)\n",
    "    output[input>(cutoff)] = 1\n",
    "    output[input<=(cutoff)] = 0\n",
    "    return output\n",
    "\n",
    "# generating intial 5 frame input for predictions\n",
    "rand_case = np.random.randint((len(val_dataset)))\n",
    "print(f\"Random case: {rand_case}\")\n",
    "example_x = val_dataset[rand_case,:,:,:,0:5]\n",
    "x_in = np.expand_dims(example_x[0:numFrames,...],axis=0)\n",
    "\n",
    "# loop to continuously make prediction (based on lastest 5 frames)\n",
    "for i in tqdm(range(64), desc=\"Plotting and Saving figures ...\"):\n",
    "    iter = (i+1)*500+2500\n",
    "    # prediction\n",
    "    new_prediction = model.predict(x_in,verbose=\"0\")\n",
    "    # phi = push(new_prediction[0,0,:,:,0],0.2)\n",
    "    # phi = np.round(new_prediction[0,0,:,:,0])\n",
    "    phi = new_prediction[0,0,:,:,0]\n",
    "    tips = np.round(eng.generate_tips_for_python(matlab.double(np.array(phi).astype('float64')),iter)) # calc tips using matlab algorithm\n",
    "    # tips = example_x[i+5,:,:,1]\n",
    "    # tips = push(new_prediction[0,0,:,:,1],0.5)\n",
    "    tub = new_prediction[0,0,:,:,2]\n",
    "    tempr = new_prediction[0,0,:,:,3]\n",
    "    theta = new_prediction[0,0,:,:,4]\n",
    "\n",
    "    # plot prediction\n",
    "    plt.figure(figsize=(25, 12), dpi=60)\n",
    "    plt.gcf().set_facecolor(\"white\")\n",
    "    plt.subplot(3,4,1)\n",
    "    plt.imshow(phi, cmap='jet')\n",
    "    plt.colorbar()\n",
    "    plt.title(f\"Pred Phi at iter {iter}\", fontweight='bold')\n",
    "    plt.subplot(3,4,2)\n",
    "    plt.imshow(tips, cmap='jet')\n",
    "    plt.colorbar()\n",
    "    plt.title(f\"Pred Tips at iter {iter}\", fontweight='bold')\n",
    "    plt.subplot(3,4,3)\n",
    "    plt.imshow(tub, cmap='jet')\n",
    "    plt.colorbar()\n",
    "    plt.title(f\"Pred Tubulin at iter {iter}\", fontweight='bold')\n",
    "    plt.subplot(3,4,4)\n",
    "    plt.imshow(tempr, cmap='jet')\n",
    "    plt.colorbar()\n",
    "    plt.title(f\"Pred Tempr at iter {iter}\", fontweight='bold')\n",
    "    # plot ground truth\n",
    "    plt.subplot(3,4,5)\n",
    "    plt.imshow(example_x[i+5,:,:,0], cmap='jet')\n",
    "    plt.colorbar()\n",
    "    plt.title(f\"Ground Truth phi at iter {iter}\", fontweight='bold')\n",
    "    plt.subplot(3,4,6)\n",
    "    plt.imshow(example_x[i+5,:,:,1], cmap='jet')\n",
    "    plt.colorbar()\n",
    "    plt.title(f\"Ground Truth Tips at iter {iter}\", fontweight='bold')\n",
    "    plt.subplot(3,4,7)\n",
    "    plt.imshow(example_x[i+5,:,:,2], cmap='jet')\n",
    "    plt.colorbar()\n",
    "    plt.title(f\"Ground Truth Tubulin at iter {iter}\", fontweight='bold')\n",
    "    plt.subplot(3,4,8)\n",
    "    plt.imshow(example_x[i+5,:,:,3], cmap='jet')\n",
    "    plt.colorbar()\n",
    "    plt.title(f\"Ground Truth Tempr at iter {iter}\", fontweight='bold')\n",
    "    # calc mean relative error\n",
    "    mre_phi = get_mre(phi,example_x[i+5,:,:,0])\n",
    "    mre_tips = get_mre(tips,example_x[i+5,:,:,1])\n",
    "    mre_tempr = get_mre(tempr,example_x[i+5,:,:,2])\n",
    "    mre_tub = get_mre(tub,example_x[i+5,:,:,3])\n",
    "    mre_theta = get_mre(theta,example_x[i+5,:,:,4])\n",
    "    # plot error\n",
    "    plt.subplot(3,4,9)\n",
    "    plt.imshow(phi-example_x[i+5,:,:,0], cmap='jet')\n",
    "    plt.colorbar()\n",
    "    plt.title(f\"Absolute phi at iter {iter}\", fontweight='bold')\n",
    "    plt.xlabel(f\"MRE error: {mre_phi}\")\n",
    "    plt.subplot(3,4,10)\n",
    "    plt.imshow(tips-example_x[i+5,:,:,1], cmap='jet')\n",
    "    plt.colorbar()\n",
    "    plt.title(f\"Absolute Tips at iter {iter}\", fontweight='bold')\n",
    "    plt.xlabel(f\"MRE error: {mre_tips}\")\n",
    "    plt.subplot(3,4,11)\n",
    "    plt.imshow(tub-example_x[i+5,:,:,2], cmap='jet')\n",
    "    plt.colorbar()\n",
    "    plt.title(f\"Absolute Tubulin at iter {iter}\", fontweight='bold')\n",
    "    plt.xlabel(f\"MRE error: {mre_tempr}\")\n",
    "    plt.subplot(3,4,12)\n",
    "    plt.imshow(tempr-example_x[i+5,:,:,3], cmap='jet')\n",
    "    plt.colorbar()\n",
    "    plt.title(f\"Absolute Tempr at iter {iter}\", fontweight='bold')\n",
    "    plt.xlabel(f\"MRE error: {mre_tub}\")\n",
    "    # save fig\n",
    "    plt.savefig(f\"gif/{iter:05d}.png\")\n",
    "    # plt.show()\n",
    "\n",
    "    # update prediction for later use as input (shifting)\n",
    "    tmp_var = copy.copy(new_prediction)\n",
    "    tmp_var[0,-1,:,:,0] = phi\n",
    "    tmp_var[0,-1,:,:,1] = tips\n",
    "    tmp = np.zeros(x_in.shape)\n",
    "    for j in range(numFrames-1):\n",
    "        tmp[0,j,...] = x_in[0,j+1,...]\n",
    "    tmp[0,-1,:,:,:] = tmp_var\n",
    "    x_in = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "conv_lstm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "3ef443919b3ee49497caa0ae1c9dcd325c651b678aa5033135de9f40fcfd4216"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
